{"system_prompt": "You are an expert in programming, you're so good at code navigation inside large repository. Try to combine different tools to seek related information to the query inside the project. Some good combinations of tools could be get_folder_structure -> find symbols of each file inside the directory. Semantic search -> exact code search -> go to definition and etc. If you know exactly the name of the symbol, you can use code_search tool or if you know the line and the name of the symbol, you can use go_to_definition tool. Try to avoid using open_file tool frequently (use the get all symbols instead). Respond to the human as helpfully and accurately as possible. Consider use other tools if the results returned is not cleared enough or failed for the query. You have access to the following tools:\n\ncode_search: Useful when you want to find all matched identifiers (variable, function, class name) from a python repository, primarily used for class, function search. The results\n    are mixed and not sorted by any criteria. So considered using this when you want to find all possible candidates for a given name. Otherwise, consider using other tools for more precise results, args: {'names': {'title': 'Names', 'description': 'The names of the identifiers to search', 'type': 'array', 'items': {'type': 'string'}}}\nSemantic Code Search: useful for when the query is a sentance, semantic and vague. If exact search such as code search failed after multiple tries, try this, args: {'tool_input': {'type': 'string'}}\ngo_to_definition: Useful when you want to find the definition of a symbol inside a code snippet if the current context is not cleared enough such as \n    0 import matplotlib.pyplot as plt\n    1 class Directory(object):\n    2\n    3    def add_member(self, id, name):\n    4        self.members[id] = plt.figure() we might want to find the definition of plt.figure() invoke with params (\"figure\", 4, 'test.py'), args: {'word': {'title': 'Word', 'type': 'string'}, 'line': {'title': 'Line', 'type': 'integer'}, 'relative_path': {'title': 'Relative Path', 'type': 'string'}}\nfind_all_references: Given a code snippet that contains target symbol, find all references of this symbol inside the project.\n    , args: {'word': {'title': 'Word', 'type': 'string'}, 'line': {'title': 'Line', 'type': 'integer'}, 'relative_path': {'title': 'Relative Path', 'type': 'string'}, 'reranking': {'title': 'Reranking', 'default': False, 'type': 'boolean'}, 'query': {'title': 'Query', 'default': '', 'type': 'string'}}\nget_all_symbols: Useful when you want to find all symbols (functions, classes, methods) of a python file, args: {'path_to_file': {'title': 'Path To File', 'type': 'string'}, 'verbose_level': {'title': 'Verbose Level', 'default': 1, 'type': 'integer'}}\nget_folder_structure: Useful when you want to explore the tree structure of a folder, good for initial exploration with knowing the parent folder name. Remember to provide the relative path correctly.\n    , args: {'relative_path': {'title': 'Relative Path', 'type': 'string'}, 'level': {'title': 'Level', 'default': 2, 'type': 'integer'}}\nopen_file: Useful when you want to open a file inside a repo, use this tool only when it's very necessary, usually a main or server or training script. Consider combinining other alternative tools such as GetAllSymbols and CodeSearch to save the number of tokens for other cases., args: {'relative_file_path': {'title': 'Relative File Path', 'type': 'string'}, 'max_new_line': {'title': 'Max New Line', 'default': 500, 'type': 'integer'}}\n\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n\nValid \"action\" values: \"Final Answer\" or code_search, Semantic Code Search, go_to_definition, find_all_references, get_all_symbols, get_folder_structure, open_file\n\nProvide only ONE action per $JSON_BLOB, as shown:\n\n```\n{\n  \"action\": $TOOL_NAME,\n  \"action_input\": $INPUT\n}\n```\n\nFollow this format:\n\nQuestion: input question to answer\nThought: consider previous and subsequent steps, notes down some useful information (like code snippet) from observation\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Final response to human\"\n}\n```\n\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if you have gathered enough information from the repository. Format is Action:```$JSON_BLOB```then Observation:.", "human_message": "Human request: how to create a multi-extension FITS (MEF) file from scratch using `astropy.io.fits (please generate the usage code)\n\nPrevious steps: steps=[]\n\nCurrent objective: value=\"Use the code_search tool with 'astropy.io.fits' and 'create' as the search terms to find relevant functions or methods for creating a multi-extension FITS (MEF) file.\"\n\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\nAction:\n```\n{\n  \"action\": \"code_search\",\n  \"action_input\": {\n    \"names\": [\"astropy.io.fits\", \"create\"]\n  }\n}\n```\n\nObservation: {'astropy.io.fits': [{'name': 'fits', 'full_name': 'astropy.io.fits', 'documentation': None, 'implementation': 'module fits'}], 'create': []}\nThought:Thought: The code_search tool did not return any specific functions or methods related to creating a multi-extension FITS (MEF) file using `astropy.io.fits`. The term \"create\" seems too generic and did not yield useful results. Since `astropy.io.fits` is a module, I will try to find all symbols within this module to see if there are any functions or classes that could be used to create a MEF file.\n\nAction:\n```\n{\n  \"action\": \"code_search\",\n  \"action_input\": {\n    \"names\": [\"HDUList\"]\n  }\n}\n```\n\n\nObservation: {'HDUList': [{'name': 'HDUList', 'full_name': 'astropy.io.fits.hdu.hdulist.HDUList', 'documentation': 'HDU list class.  This is the top-level FITS object.  When a FITS\\nfile is opened, a `HDUList` object is returned.', 'implementation': '236 class HDUList(list, _Verify):\\n237     \"\"\"\\n238     HDU list class.  This is the top-level FITS object.  When a FITS\\n239     file is opened, a `HDUList` object is returned.\\n240     \"\"\"\\n241 \\n242     def __init__(self, hdus=[], file=None):\\n243         \"\"\"\\n244         Construct a `HDUList` object.\\n245 \\n246         Parameters\\n247         ----------\\n248         hdus : BaseHDU or sequence thereof, optional\\n249             The HDU object(s) to comprise the `HDUList`.  Should be\\n250             instances of HDU classes like `ImageHDU` or `BinTableHDU`.\\n251 \\n252         file : file-like, bytes, optional\\n253             The opened physical file associated with the `HDUList`\\n254             or a bytes object containing the contents of the FITS\\n255             file.\\n256         \"\"\"\\n257         if isinstance(file, bytes):\\n258             self._data = file\\n259             self._file = None\\n260         else:\\n261             self._file = file\\n262             self._data = None\\n263 \\n264         # For internal use only--the keyword args passed to fitsopen /\\n265         # HDUList.fromfile/string when opening the file\\n266         self._open_kwargs = {}\\n267         self._in_read_next_hdu = False\\n268 \\n269         # If we have read all the HDUs from the file or not\\n270         # The assumes that all HDUs have been written when we first opened the\\n271         # file; we do not currently support loading additional HDUs from a file\\n272         # while it is being streamed to.  In the future that might be supported\\n273         # but for now this is only used for the purpose of lazy-loading of\\n274         # existing HDUs.\\n275         if file is None:\\n276             self._read_all = True\\n277         elif self._file is not None:\\n278             # Should never attempt to read HDUs in ostream mode\\n279             self._read_all = self._file.mode == \"ostream\"\\n280         else:\\n281             self._read_all = False\\n282 \\n283         if hdus is None:\\n284             hdus = []\\n285 \\n286         # can take one HDU, as well as a list of HDU\\'s as input\\n287         if isinstance(hdus, _ValidHDU):\\n288             hdus = [hdus]\\n289         elif not isinstance(hdus, (HDUList, list)):\\n290             raise TypeError(\"Invalid input for HDUList.\")\\n291 \\n292         for idx, hdu in enumerate(hdus):\\n293             if not isinstance(hdu, _BaseHDU):\\n294                 raise TypeError(f\"Element {idx} in the HDUList input is not an HDU.\")\\n295 \\n296         super().__init__(hdus)\\n297 \\n298         if file is None:\\n299             # Only do this when initializing from an existing list of HDUs\\n300             # When initializing from a file, this will be handled by the\\n301             # append method after the first HDU is read\\n302             self.update_extend()\\n303 \\n304     def __len__(self):\\n305         if not self._in_read_next_hdu:\\n306             self.readall()\\n307 \\n308         return super().__len__()\\n309 \\n310     def __repr__(self):\\n311         # Special case: if the FITS file is located on a remote file system\\n312         # and has not been fully read yet, we return a simplified repr to\\n313         # avoid downloading the entire file.  We can tell that a file is remote\\n314         # from the fact that the ``fsspec`` package was used to open it.\\n315         is_fsspec_file = self._file and \"fsspec\" in str(\\n316             self._file._file.__class__.__bases__\\n317         )\\n318         if not self._read_all and is_fsspec_file:\\n319             return f\"{type(self)} (partially read)\"\\n320 \\n321         # In order to correctly repr an HDUList we need to load all the\\n322         # HDUs as well\\n323         self.readall()\\n324 \\n325         return super().__repr__()\\n326 \\n327     def __iter__(self):\\n328         # While effectively this does the same as:\\n329         # for idx in range(len(self)):\\n330         #     yield self[idx]\\n331         # the more complicated structure is here to prevent the use of len(),\\n332         # which would break the lazy loading\\n333         for idx in itertools.count():\\n334             try:\\n335                 yield self[idx]\\n336             except IndexError:\\n337                 break\\n338 \\n339     def __getitem__(self, key):\\n340         \"\"\"\\n341         Get an HDU from the `HDUList`, indexed by number or name.\\n342         \"\"\"\\n343         # If the key is a slice we need to make sure the necessary HDUs\\n344         # have been loaded before passing the slice on to super.\\n345         if isinstance(key, slice):\\n346             max_idx = key.stop\\n347             # Check for and handle the case when no maximum was\\n348             # specified (e.g. [1:]).\\n349             if max_idx is None:\\n350                 # We need all of the HDUs, so load them\\n351                 # and reset the maximum to the actual length.\\n352                 max_idx = len(self)\\n353 \\n354             # Just in case the max_idx is negative...\\n355             max_idx = self._positive_index_of(max_idx)\\n356 \\n357             number_loaded = super().__len__()\\n358 \\n359             if max_idx >= number_loaded:\\n360                 # We need more than we have, try loading up to and including\\n361                 # max_idx. Note we do not try to be clever about skipping HDUs\\n362                 # even though key.step might conceivably allow it.\\n363                 for i in range(number_loaded, max_idx):\\n364                     # Read until max_idx or to the end of the file, whichever\\n365                     # comes first.\\n366                     if not self._read_next_hdu():\\n367                         break\\n368 \\n369             try:\\n370                 hdus = super().__getitem__(key)\\n371             except IndexError as e:\\n372                 # Raise a more helpful IndexError if the file was not fully read.\\n373                 if self._read_all:\\n374                     raise e\\n375                 else:\\n376                     raise IndexError(\\n377                         \"HDU not found, possibly because the index \"\\n378                         \"is out of range, or because the file was \"\\n379                         \"closed before all HDUs were read\"\\n380                     )\\n381             else:\\n382                 return HDUList(hdus)\\n383 \\n384         # Originally this used recursion, but hypothetically an HDU with\\n385         # a very large number of HDUs could blow the stack, so use a loop\\n386         # instead\\n387         try:\\n388             return self._try_while_unread_hdus(\\n389                 super().__getitem__, self._positive_index_of(key)\\n390             )\\n391         except IndexError as e:\\n392             # Raise a more helpful IndexError if the file was not fully read.\\n393             if self._read_all:\\n394                 raise e\\n395             else:\\n396                 raise IndexError(\\n397                     \"HDU not found, possibly because the index \"\\n398                     \"is out of range, or because the file was \"\\n399                     \"closed before all HDUs were read\"\\n400                 )\\n401 \\n402     def __contains__(self, item):\\n403         \"\"\"\\n404         Returns `True` if ``item`` is an ``HDU`` _in_ ``self`` or a valid\\n405         extension specification (e.g., integer extension number, extension\\n406         name, or a tuple of extension name and an extension version)\\n407         of a ``HDU`` in ``self``.\\n408 \\n409         \"\"\"\\n410         try:\\n411             self._try_while_unread_hdus(self.index_of, item)\\n412         except (KeyError, ValueError):\\n413             return False\\n414 \\n415         return True\\n416 \\n417     def __setitem__(self, key, hdu):\\n418         \"\"\"\\n419         Set an HDU to the `HDUList`, indexed by number or name.\\n420         \"\"\"\\n421         _key = self._positive_index_of(key)\\n422         if isinstance(hdu, (slice, list)):\\n423             if _is_int(_key):\\n424                 raise ValueError(\"An element in the HDUList must be an HDU.\")\\n425             for item in hdu:\\n426                 if not isinstance(item, _BaseHDU):\\n427                     raise ValueError(f\"{item} is not an HDU.\")\\n428         else:\\n429             if not isinstance(hdu, _BaseHDU):\\n430                 raise ValueError(f\"{hdu} is not an HDU.\")\\n431 \\n432         try:\\n433             self._try_while_unread_hdus(super().__setitem__, _key, hdu)\\n434         except IndexError:\\n435             raise IndexError(f\"Extension {key} is out of bound or not found.\")\\n436 \\n437         self._resize = True\\n438         self._truncate = False\\n439 \\n440     def __delitem__(self, key):\\n441         \"\"\"\\n442         Delete an HDU from the `HDUList`, indexed by number or name.\\n443         \"\"\"\\n444         if isinstance(key, slice):\\n445             end_index = len(self)\\n446         else:\\n447             key = self._positive_index_of(key)\\n448             end_index = len(self) - 1\\n449 \\n450         self._try_while_unread_hdus(super().__delitem__, key)\\n451 \\n452         if key == end_index or key == -1 and not self._resize:\\n453             self._truncate = True\\n454         else:\\n455             self._truncate = False\\n456             self._resize = True\\n457 \\n458     # Support the \\'with\\' statement\\n459     def __enter__(self):\\n460         return self\\n461 \\n462     def __exit__(self, type, value, traceback):\\n463         output_verify = self._open_kwargs.get(\"output_verify\", \"exception\")\\n464         self.close(output_verify=output_verify)\\n465 \\n466     @classmethod\\n467     def fromfile(\\n468         cls,\\n469         fileobj,\\n470         mode=None,\\n471         memmap=None,\\n472         save_backup=False,\\n473         cache=True,\\n474         lazy_load_hdus=True,\\n475         ignore_missing_simple=False,\\n476         **kwargs,\\n477     ):\\n478         \"\"\"\\n479         Creates an `HDUList` instance from a file-like object.\\n480 \\n481         The actual implementation of ``fitsopen()``, and generally shouldn\\'t\\n482         be used directly.  Use :func:`open` instead (and see its\\n483         documentation for details of the parameters accepted by this method).\\n484         \"\"\"\\n485         return cls._readfrom(\\n486             fileobj=fileobj,\\n487             mode=mode,\\n488             memmap=memmap,\\n489             save_backup=save_backup,\\n490             cache=cache,\\n491             ignore_missing_simple=ignore_missing_simple,\\n492             lazy_load_hdus=lazy_load_hdus,\\n493             **kwargs,\\n494         )\\n495 \\n496     @classmethod\\n497     def fromstring(cls, data, **kwargs):\\n498         \"\"\"\\n499         Creates an `HDUList` instance from a string or other in-memory data\\n500         buffer containing an entire FITS file.  Similar to\\n501         :meth:`HDUList.fromfile`, but does not accept the mode or memmap\\n502         arguments, as they are only relevant to reading from a file on disk.\\n503 \\n504         This is useful for interfacing with other libraries such as CFITSIO,\\n505         and may also be useful for streaming applications.\\n506 \\n507         Parameters\\n508         ----------\\n509         data : str, buffer-like, etc.\\n510             A string or other memory buffer containing an entire FITS file.\\n511             Buffer-like objects include :class:`~bytes`, :class:`~bytearray`,\\n512             :class:`~memoryview`, and :class:`~numpy.ndarray`.\\n513             It should be noted that if that memory is read-only (such as a\\n514             Python string) the returned :class:`HDUList`\\'s data portions will\\n515             also be read-only.\\n516         **kwargs : dict\\n517             Optional keyword arguments.  See\\n518             :func:`astropy.io.fits.open` for details.\\n519 \\n520         Returns\\n521         -------\\n522         hdul : HDUList\\n523             An :class:`HDUList` object representing the in-memory FITS file.\\n524         \"\"\"\\n525         try:\\n526             # Test that the given object supports the buffer interface by\\n527             # ensuring an ndarray can be created from it\\n528             np.ndarray((), dtype=\"ubyte\", buffer=data)\\n529         except TypeError:\\n530             raise TypeError(\\n531                 f\"The provided object {data} does not contain an underlying \"\\n532                 \"memory buffer.  fromstring() requires an object that \"\\n533                 \"supports the buffer interface such as bytes, buffer, \"\\n534                 \"memoryview, ndarray, etc.  This restriction is to ensure \"\\n535                 \"that efficient access to the array/table data is possible.\"\\n536             )\\n537 \\n538         return cls._readfrom(data=data, **kwargs)\\n539 \\n540     def fileinfo(self, index):\\n541         \"\"\"\\n542         Returns a dictionary detailing information about the locations\\n543         of the indexed HDU within any associated file.  The values are\\n544         only valid after a read or write of the associated file with\\n545         no intervening changes to the `HDUList`.\\n546 \\n547         Parameters\\n548         ----------\\n549         index : int\\n550             Index of HDU for which info is to be returned.\\n551 \\n552         Returns\\n553         -------\\n554         fileinfo : dict or None\\n555 \\n556             The dictionary details information about the locations of\\n557             the indexed HDU within an associated file.  Returns `None`\\n558             when the HDU is not associated with a file.\\n559 \\n560             Dictionary contents:\\n561 \\n562             ========== ========================================================\\n563             Key        Value\\n564             ========== ========================================================\\n565             file       File object associated with the HDU\\n566             filename   Name of associated file object\\n567             filemode   Mode in which the file was opened (readonly,\\n568                        update, append, denywrite, ostream)\\n569             resized    Flag that when `True` indicates that the data has been\\n570                        resized since the last read/write so the returned values\\n571                        may not be valid.\\n572             hdrLoc     Starting byte location of header in file\\n573             datLoc     Starting byte location of data block in file\\n574             datSpan    Data size including padding\\n575             ========== ========================================================\\n576 \\n577         \"\"\"\\n578         if self._file is not None:\\n579             output = self[index].fileinfo()\\n580 \\n581             if not output:\\n582                 # OK, the HDU associated with this index is not yet\\n583                 # tied to the file associated with the HDUList.  The only way\\n584                 # to get the file object is to check each of the HDU\\'s in the\\n585                 # list until we find the one associated with the file.\\n586                 f = None\\n587 \\n588                 for hdu in self:\\n589                     info = hdu.fileinfo()\\n590 \\n591                     if info:\\n592                         f = info[\"file\"]\\n593                         fm = info[\"filemode\"]\\n594                         break\\n595 \\n596                 output = {\\n597                     \"file\": f,\\n598                     \"filemode\": fm,\\n599                     \"hdrLoc\": None,\\n600                     \"datLoc\": None,\\n601                     \"datSpan\": None,\\n602                 }\\n603 \\n604             output[\"filename\"] = self._file.name\\n605             output[\"resized\"] = self._wasresized()\\n606         else:\\n607             output = None\\n608 \\n609         return output\\n610 \\n611     def __copy__(self):\\n612         \"\"\"\\n613         Return a shallow copy of an HDUList.\\n614 \\n615         Returns\\n616         -------\\n617         copy : `HDUList`\\n618             A shallow copy of this `HDUList` object.\\n619 \\n620         \"\"\"\\n621         return self[:]\\n622 \\n623     # Syntactic sugar for `__copy__()` magic method\\n624     copy = __copy__\\n625 \\n626     def __deepcopy__(self, memo=None):\\n627         return HDUList([hdu.copy() for hdu in self])\\n628 \\n629     def pop(self, index=-1):\\n630         \"\"\"Remove an item from the list and return it.\\n631 \\n632         Parameters\\n633         ----------\\n634         index : int, str, tuple of (string, int), optional\\n635             An integer value of ``index`` indicates the position from which\\n636             ``pop()`` removes and returns an HDU. A string value or a tuple\\n637             of ``(string, int)`` functions as a key for identifying the\\n638             HDU to be removed and returned. If ``key`` is a tuple, it is\\n639             of the form ``(key, ver)`` where ``ver`` is an ``EXTVER``\\n640             value that must match the HDU being searched for.\\n641 \\n642             If the key is ambiguous (e.g. there are multiple \\'SCI\\' extensions)\\n643             the first match is returned.  For a more precise match use the\\n644             ``(name, ver)`` pair.\\n645 \\n646             If even the ``(name, ver)`` pair is ambiguous the numeric index\\n647             must be used to index the duplicate HDU.\\n648 \\n649         Returns\\n650         -------\\n651         hdu : BaseHDU\\n652             The HDU object at position indicated by ``index`` or having name\\n653             and version specified by ``index``.\\n654         \"\"\"\\n655         # Make sure that HDUs are loaded before attempting to pop\\n656         self.readall()\\n657         list_index = self.index_of(index)\\n658         return super().pop(list_index)\\n659 \\n660     def insert(self, index, hdu):\\n661         \"\"\"\\n662         Insert an HDU into the `HDUList` at the given ``index``.\\n663 \\n664         Parameters\\n665         ----------\\n666         index : int\\n667             Index before which to insert the new HDU.\\n668 \\n669         hdu : BaseHDU\\n670             The HDU object to insert\\n671         \"\"\"\\n672         if not isinstance(hdu, _BaseHDU):\\n673             raise ValueError(f\"{hdu} is not an HDU.\")\\n674 \\n675         num_hdus = len(self)\\n676 \\n677         if index == 0 or num_hdus == 0:\\n678             if num_hdus != 0:\\n679                 # We are inserting a new Primary HDU so we need to\\n680                 # make the current Primary HDU into an extension HDU.\\n681                 if isinstance(self[0], GroupsHDU):\\n682                     raise ValueError(\\n683                         \"The current Primary HDU is a GroupsHDU.  \"\\n684                         \"It can\\'t be made into an extension HDU, \"\\n685                         \"so another HDU cannot be inserted before it.\"\\n686                     )\\n687 \\n688                 hdu1 = ImageHDU(self[0].data, self[0].header)\\n689 \\n690                 # Insert it into position 1, then delete HDU at position 0.\\n691                 super().insert(1, hdu1)\\n692                 super().__delitem__(0)\\n693 \\n694             if not isinstance(hdu, (PrimaryHDU, _NonstandardHDU)):\\n695                 # You passed in an Extension HDU but we need a Primary HDU.\\n696                 # If you provided an ImageHDU then we can convert it to\\n697                 # a primary HDU and use that.\\n698                 if isinstance(hdu, ImageHDU):\\n699                     hdu = PrimaryHDU(hdu.data, hdu.header)\\n700                 else:\\n701                     # You didn\\'t provide an ImageHDU so we create a\\n702                     # simple Primary HDU and append that first before\\n703                     # we append the new Extension HDU.\\n704                     phdu = PrimaryHDU()\\n705 \\n706                     super().insert(0, phdu)\\n707                     index = 1\\n708         else:\\n709             if isinstance(hdu, GroupsHDU):\\n710                 raise ValueError(\"A GroupsHDU must be inserted as a Primary HDU.\")\\n711 \\n712             if isinstance(hdu, PrimaryHDU):\\n713                 # You passed a Primary HDU but we need an Extension HDU\\n714                 # so create an Extension HDU from the input Primary HDU.\\n715                 hdu = ImageHDU(hdu.data, hdu.header)\\n716 \\n717         super().insert(index, hdu)\\n718         hdu._new = True\\n719         self._resize = True\\n720         self._truncate = False\\n721         # make sure the EXTEND keyword is in primary HDU if there is extension\\n722         self.update_extend()\\n723 \\n724     def append(self, hdu):\\n725         \"\"\"\\n726         Append a new HDU to the `HDUList`.\\n727 \\n728         Parameters\\n729         ----------\\n730         hdu : BaseHDU\\n731             HDU to add to the `HDUList`.\\n732         \"\"\"\\n733         if not isinstance(hdu, _BaseHDU):\\n734             raise ValueError(\"HDUList can only append an HDU.\")\\n735 \\n736         if len(self) > 0:\\n737             if isinstance(hdu, GroupsHDU):\\n738                 raise ValueError(\"Can\\'t append a GroupsHDU to a non-empty HDUList\")\\n739 \\n740             if isinstance(hdu, PrimaryHDU):\\n741                 # You passed a Primary HDU but we need an Extension HDU\\n742                 # so create an Extension HDU from the input Primary HDU.\\n743                 # TODO: This isn\\'t necessarily sufficient to copy the HDU;\\n744                 # _header_offset and friends need to be copied too.\\n745                 hdu = ImageHDU(hdu.data, hdu.header)\\n746         else:\\n747             if not isinstance(hdu, (PrimaryHDU, _NonstandardHDU)):\\n748                 # You passed in an Extension HDU but we need a Primary\\n749                 # HDU.\\n750                 # If you provided an ImageHDU then we can convert it to\\n751                 # a primary HDU and use that.\\n752                 if isinstance(hdu, ImageHDU):\\n753                     hdu = PrimaryHDU(hdu.data, hdu.header)\\n754                 else:\\n755                     # You didn\\'t provide an ImageHDU so we create a\\n756                     # simple Primary HDU and append that first before\\n757                     # we append the new Extension HDU.\\n758                     phdu = PrimaryHDU()\\n759                     super().append(phdu)\\n760 \\n761         super().append(hdu)\\n762         hdu._new = True\\n763         self._resize = True\\n764         self._truncate = False\\n765 \\n766         # make sure the EXTEND keyword is in primary HDU if there is extension\\n767         self.update_extend()\\n768 \\n769     def index_of(self, key):\\n770         \"\"\"\\n771         Get the index of an HDU from the `HDUList`.\\n772 \\n773         Parameters\\n774         ----------\\n775         key : int, str, tuple of (string, int) or BaseHDU\\n776             The key identifying the HDU.  If ``key`` is a tuple, it is of the\\n777             form ``(name, ver)`` where ``ver`` is an ``EXTVER`` value that must\\n778             match the HDU being searched for.\\n779 \\n780             If the key is ambiguous (e.g. there are multiple \\'SCI\\' extensions)\\n781             the first match is returned.  For a more precise match use the\\n782             ``(name, ver)`` pair.\\n783 \\n784             If even the ``(name, ver)`` pair is ambiguous (it shouldn\\'t be\\n785             but it\\'s not impossible) the numeric index must be used to index\\n786             the duplicate HDU.\\n787 \\n788             When ``key`` is an HDU object, this function returns the\\n789             index of that HDU object in the ``HDUList``.\\n790 \\n791         Returns\\n792         -------\\n793         index : int\\n794             The index of the HDU in the `HDUList`.\\n795 \\n796         Raises\\n797         ------\\n798         ValueError\\n799             If ``key`` is an HDU object and it is not found in the ``HDUList``.\\n800         KeyError\\n801             If an HDU specified by the ``key`` that is an extension number,\\n802             extension name, or a tuple of extension name and version is not\\n803             found in the ``HDUList``.\\n804 \\n805         \"\"\"\\n806         if _is_int(key):\\n807             return key\\n808         elif isinstance(key, tuple):\\n809             _key, _ver = key\\n810         elif isinstance(key, _BaseHDU):\\n811             return self.index(key)\\n812         else:\\n813             _key = key\\n814             _ver = None\\n815 \\n816         if not isinstance(_key, str):\\n817             raise KeyError(\\n818                 \"{} indices must be integers, extension names as strings, \"\\n819                 \"or (extname, version) tuples; got {}\"\\n820                 \"\".format(self.__class__.__name__, _key)\\n821             )\\n822 \\n823         _key = (_key.strip()).upper()\\n824 \\n825         found = None\\n826         for idx, hdu in enumerate(self):\\n827             name = hdu.name\\n828             if isinstance(name, str):\\n829                 name = name.strip().upper()\\n830             # \\'PRIMARY\\' should always work as a reference to the first HDU\\n831             if (name == _key or (_key == \"PRIMARY\" and idx == 0)) and (\\n832                 _ver is None or _ver == hdu.ver\\n833             ):\\n834                 found = idx\\n835                 break\\n836 \\n837         if found is None:\\n838             raise KeyError(f\"Extension {key!r} not found.\")\\n839         else:\\n840             return found\\n841 \\n842     def _positive_index_of(self, key):\\n843         \"\"\"\\n844         Same as index_of, but ensures always returning a positive index\\n845         or zero.\\n846 \\n847         (Really this should be called non_negative_index_of but it felt\\n848         too long.)\\n849 \\n850         This means that if the key is a negative integer, we have to\\n851         convert it to the corresponding positive index.  This means\\n852         knowing the length of the HDUList, which in turn means loading\\n853         all HDUs.  Therefore using negative indices on HDULists is inherently\\n854         inefficient.\\n855         \"\"\"\\n856         index = self.index_of(key)\\n857 \\n858         if index >= 0:\\n859             return index\\n860 \\n861         if abs(index) > len(self):\\n862             raise IndexError(f\"Extension {index} is out of bound or not found.\")\\n863 \\n864         return len(self) + index\\n865 \\n866     def readall(self):\\n867         \"\"\"\\n868         Read data of all HDUs into memory.\\n869         \"\"\"\\n870         while self._read_next_hdu():\\n871             pass\\n872 \\n873     @ignore_sigint\\n874     def flush(self, output_verify=\"fix\", verbose=False):\\n875         \"\"\"\\n876         Force a write of the `HDUList` back to the file (for append and\\n877         update modes only).\\n878 \\n879         Parameters\\n880         ----------\\n881         output_verify : str\\n882             Output verification option.  Must be one of ``\"fix\"``,\\n883             ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\\n884             ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\\n885             ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\\n886             (e.g. ``\"fix+warn\"``).  See :ref:`astropy:verify` for more info.\\n887 \\n888         verbose : bool\\n889             When `True`, print verbose messages\\n890         \"\"\"\\n891         if self._file.mode not in (\"append\", \"update\", \"ostream\"):\\n892             warnings.warn(\\n893                 f\"Flush for \\'{self._file.mode}\\' mode is not supported.\",\\n894                 AstropyUserWarning,\\n895             )\\n896             return\\n897 \\n898         save_backup = self._open_kwargs.get(\"save_backup\", False)\\n899         if save_backup and self._file.mode in (\"append\", \"update\"):\\n900             filename = self._file.name\\n901             if os.path.exists(filename):\\n902                 # The file doesn\\'t actually exist anymore for some reason\\n903                 # then there\\'s no point in trying to make a backup\\n904                 backup = filename + \".bak\"\\n905                 idx = 1\\n906                 while os.path.exists(backup):\\n907                     backup = filename + \".bak.\" + str(idx)\\n908                     idx += 1\\n909                 warnings.warn(\\n910                     f\"Saving a backup of {filename} to {backup}.\", AstropyUserWarning\\n911                 )\\n912                 try:\\n913                     shutil.copy(filename, backup)\\n914                 except OSError as exc:\\n915                     raise OSError(\\n916                         f\"Failed to save backup to destination {filename}\"\\n917                     ) from exc\\n918 \\n919         self.verify(option=output_verify)\\n920 \\n921         if self._file.mode in (\"append\", \"ostream\"):\\n922             for hdu in self:\\n923                 if verbose:\\n924                     try:\\n925                         extver = str(hdu._header[\"extver\"])\\n926                     except KeyError:\\n927                         extver = \"\"\\n928 \\n929                 # only append HDU\\'s which are \"new\"\\n930                 if hdu._new:\\n931                     hdu._prewriteto(checksum=hdu._output_checksum)\\n932                     with _free_space_check(self):\\n933                         hdu._writeto(self._file)\\n934                         if verbose:\\n935                             print(\"append HDU\", hdu.name, extver)\\n936                         hdu._new = False\\n937                     hdu._postwriteto()\\n938 \\n939         elif self._file.mode == \"update\":\\n940             self._flush_update()\\n941 \\n942     def update_extend(self):\\n943         \"\"\"\\n944         Make sure that if the primary header needs the keyword ``EXTEND`` that\\n945         it has it and it is correct.\\n946         \"\"\"\\n947         if not len(self):\\n948             return\\n949 \\n950         if not isinstance(self[0], PrimaryHDU):\\n951             # A PrimaryHDU will be automatically inserted at some point, but it\\n952             # might not have been added yet\\n953             return\\n954 \\n955         hdr = self[0].header\\n956 \\n957         def get_first_ext():\\n958             try:\\n959                 return self[1]\\n960             except IndexError:\\n961                 return None\\n962 \\n963         if \"EXTEND\" in hdr:\\n964             if not hdr[\"EXTEND\"] and get_first_ext() is not None:\\n965                 hdr[\"EXTEND\"] = True\\n966         elif get_first_ext() is not None:\\n967             if hdr[\"NAXIS\"] == 0:\\n968                 hdr.set(\"EXTEND\", True, after=\"NAXIS\")\\n969             else:\\n970                 n = hdr[\"NAXIS\"]\\n971                 hdr.set(\"EXTEND\", True, after=\"NAXIS\" + str(n))\\n972 \\n973     def writeto(\\n974         self, fileobj, output_verify=\"exception\", overwrite=False, checksum=False\\n975     ):\\n976         \"\"\"\\n977         Write the `HDUList` to a new file.\\n978 \\n979         Parameters\\n980         ----------\\n981         fileobj : str, file-like or `pathlib.Path`\\n982             File to write to.  If a file object, must be opened in a\\n983             writeable mode.\\n984 \\n985         output_verify : str\\n986             Output verification option.  Must be one of ``\"fix\"``,\\n987             ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\\n988             ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\\n989             ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\\n990             (e.g. ``\"fix+warn\"``).  See :ref:`astropy:verify` for more info.\\n991 \\n992         overwrite : bool, optional\\n993             If ``True``, overwrite the output file if it exists. Raises an\\n994             ``OSError`` if ``False`` and the output file exists. Default is\\n995             ``False``.\\n996 \\n997         checksum : bool\\n998             When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\\n999             to the headers of all HDU\\'s written to the file.\\n1000         \"\"\"\\n1001         if len(self) == 0:\\n1002             warnings.warn(\"There is nothing to write.\", AstropyUserWarning)\\n1003             return\\n1004 \\n1005         self.verify(option=output_verify)\\n1006 \\n1007         # make sure the EXTEND keyword is there if there is extension\\n1008         self.update_extend()\\n1009 \\n1010         # make note of whether the input file object is already open, in which\\n1011         # case we should not close it after writing (that should be the job\\n1012         # of the caller)\\n1013         closed = isinstance(fileobj, str) or fileobj_closed(fileobj)\\n1014 \\n1015         mode = FILE_MODES[fileobj_mode(fileobj)] if isfile(fileobj) else \"ostream\"\\n1016 \\n1017         # This can accept an open file object that\\'s open to write only, or in\\n1018         # append/update modes but only if the file doesn\\'t exist.\\n1019         fileobj = _File(fileobj, mode=mode, overwrite=overwrite)\\n1020         hdulist = self.fromfile(fileobj)\\n1021         try:\\n1022             dirname = os.path.dirname(hdulist._file.name)\\n1023         except (AttributeError, TypeError):\\n1024             dirname = None\\n1025 \\n1026         try:\\n1027             with _free_space_check(self, dirname=dirname):\\n1028                 for hdu in self:\\n1029                     hdu._prewriteto(checksum=checksum)\\n1030                     hdu._writeto(hdulist._file)\\n1031                     hdu._postwriteto()\\n1032         finally:\\n1033             hdulist.close(output_verify=output_verify, closed=closed)\\n1034 \\n1035     def close(self, output_verify=\"exception\", verbose=False, closed=True):\\n1036         \"\"\"\\n1037         Close the associated FITS file and memmap object, if any.\\n1038 \\n1039         Parameters\\n1040         ----------\\n1041         output_verify : str\\n1042             Output verification option.  Must be one of ``\"fix\"``,\\n1043             ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\\n1044             ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\\n1045             ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\\n1046             (e.g. ``\"fix+warn\"``).  See :ref:`astropy:verify` for more info.\\n1047 \\n1048         verbose : bool\\n1049             When `True`, print out verbose messages.\\n1050 \\n1051         closed : bool\\n1052             When `True`, close the underlying file object.\\n1053         \"\"\"\\n1054         try:\\n1055             if (\\n1056                 self._file\\n1057                 and self._file.mode in (\"append\", \"update\")\\n1058                 and not self._file.closed\\n1059             ):\\n1060                 self.flush(output_verify=output_verify, verbose=verbose)\\n1061         finally:\\n1062             if self._file and closed and hasattr(self._file, \"close\"):\\n1063                 self._file.close()\\n1064 \\n1065             # Give individual HDUs an opportunity to do on-close cleanup\\n1066             for hdu in self:\\n1067                 hdu._close(closed=closed)\\n1068 \\n1069     def info(self, output=None):\\n1070         \"\"\"\\n1071         Summarize the info of the HDUs in this `HDUList`.\\n1072 \\n1073         Note that this function prints its results to the console---it\\n1074         does not return a value.\\n1075 \\n1076         Parameters\\n1077         ----------\\n1078         output : file-like or bool, optional\\n1079             A file-like object to write the output to.  If `False`, does not\\n1080             output to a file and instead returns a list of tuples representing\\n1081             the HDU info.  Writes to ``sys.stdout`` by default.\\n1082         \"\"\"\\n1083         if output is None:\\n1084             output = sys.stdout\\n1085 \\n1086         if self._file is None:\\n1087             name = \"(No file associated with this HDUList)\"\\n1088         else:\\n1089             name = self._file.name\\n1090 \\n1091         results = [\\n1092             f\"Filename: {name}\",\\n1093             \"No.    Name      Ver    Type      Cards   Dimensions   Format\",\\n1094         ]\\n1095 \\n1096         format = \"{:3d}  {:10}  {:3} {:11}  {:5d}   {}   {}   {}\"\\n1097         default = (\"\", \"\", \"\", 0, (), \"\", \"\")\\n1098         for idx, hdu in enumerate(self):\\n1099             summary = hdu._summary()\\n1100             if len(summary) < len(default):\\n1101                 summary += default[len(summary) :]\\n1102             summary = (idx,) + summary\\n1103             if output:\\n1104                 results.append(format.format(*summary))\\n1105             else:\\n1106                 results.append(summary)\\n1107 \\n1108         if output:\\n1109             output.write(\"\\\\n\".join(results))\\n1110             output.write(\"\\\\n\")\\n1111             output.flush()\\n1112         else:\\n1113             return results[2:]\\n1114 \\n1115     def filename(self):\\n1116         \"\"\"\\n1117         Return the file name associated with the HDUList object if one exists.\\n1118         Otherwise returns None.\\n1119 \\n1120         Returns\\n1121         -------\\n1122         filename : str\\n1123             A string containing the file name associated with the HDUList\\n1124             object if an association exists.  Otherwise returns None.\\n1125 \\n1126         \"\"\"\\n1127         if self._file is not None:\\n1128             if hasattr(self._file, \"name\"):\\n1129                 return self._file.name\\n1130         return None\\n1131 \\n1132     @classmethod\\n1133     def _readfrom(\\n1134         cls,\\n1135         fileobj=None,\\n1136         data=None,\\n1137         mode=None,\\n1138         memmap=None,\\n1139         cache=True,\\n1140         lazy_load_hdus=True,\\n1141         ignore_missing_simple=False,\\n1142         *,\\n1143         use_fsspec=None,\\n1144         fsspec_kwargs=None,\\n1145         decompress_in_memory=False,\\n1146         **kwargs,\\n1147     ):\\n1148         \"\"\"\\n1149         Provides the implementations from HDUList.fromfile and\\n1150         HDUList.fromstring, both of which wrap this method, as their\\n1151         implementations are largely the same.\\n1152         \"\"\"\\n1153         if fileobj is not None:\\n1154             if not isinstance(fileobj, _File):\\n1155                 # instantiate a FITS file object (ffo)\\n1156                 fileobj = _File(\\n1157                     fileobj,\\n1158                     mode=mode,\\n1159                     memmap=memmap,\\n1160                     cache=cache,\\n1161                     use_fsspec=use_fsspec,\\n1162                     fsspec_kwargs=fsspec_kwargs,\\n1163                     decompress_in_memory=decompress_in_memory,\\n1164                 )\\n1165             # The Astropy mode is determined by the _File initializer if the\\n1166             # supplied mode was None\\n1167             mode = fileobj.mode\\n1168             hdulist = cls(file=fileobj)\\n1169         else:\\n1170             if mode is None:\\n1171                 # The default mode\\n1172                 mode = \"readonly\"\\n1173 \\n1174             hdulist = cls(file=data)\\n1175             # This method is currently only called from HDUList.fromstring and\\n1176             # HDUList.fromfile.  If fileobj is None then this must be the\\n1177             # fromstring case; the data type of ``data`` will be checked in the\\n1178             # _BaseHDU.fromstring call.\\n1179 \\n1180         if (\\n1181             not ignore_missing_simple\\n1182             and hdulist._file\\n1183             and hdulist._file.mode != \"ostream\"\\n1184             and hdulist._file.size > 0\\n1185         ):\\n1186             pos = hdulist._file.tell()\\n1187             # FITS signature is supposed to be in the first 30 bytes, but to\\n1188             # allow reading various invalid files we will check in the first\\n1189             # card (80 bytes).\\n1190             simple = hdulist._file.read(80)\\n1191             match_sig = simple[:29] == FITS_SIGNATURE[:-1] and simple[29:30] in (\\n1192                 b\"T\",\\n1193                 b\"F\",\\n1194             )\\n1195 \\n1196             if not match_sig:\\n1197                 # Check the SIMPLE card is there but not written correctly\\n1198                 match_sig_relaxed = re.match(rb\"SIMPLE\\\\s*=\\\\s*[T|F]\", simple)\\n1199 \\n1200                 if match_sig_relaxed:\\n1201                     warnings.warn(\\n1202                         \"Found a SIMPLE card but its format doesn\\'t\"\\n1203                         \" respect the FITS Standard\",\\n1204                         VerifyWarning,\\n1205                     )\\n1206                 else:\\n1207                     if hdulist._file.close_on_error:\\n1208                         hdulist._file.close()\\n1209                     raise OSError(\\n1210                         \"No SIMPLE card found, this file does not appear to \"\\n1211                         \"be a valid FITS file. If this is really a FITS file, \"\\n1212                         \"try with ignore_missing_simple=True\"\\n1213                     )\\n1214 \\n1215             hdulist._file.seek(pos)\\n1216 \\n1217         # Store additional keyword args that were passed to fits.open\\n1218         hdulist._open_kwargs = kwargs\\n1219 \\n1220         if fileobj is not None and fileobj.writeonly:\\n1221             # Output stream--not interested in reading/parsing\\n1222             # the HDUs--just writing to the output file\\n1223             return hdulist\\n1224 \\n1225         # Make sure at least the PRIMARY HDU can be read\\n1226         read_one = hdulist._read_next_hdu()\\n1227 \\n1228         # If we\\'re trying to read only and no header units were found,\\n1229         # raise an exception\\n1230         if not read_one and mode in (\"readonly\", \"denywrite\"):\\n1231             # Close the file if necessary (issue #6168)\\n1232             if hdulist._file.close_on_error:\\n1233                 hdulist._file.close()\\n1234 \\n1235             raise OSError(\"Empty or corrupt FITS file\")\\n1236 \\n1237         if not lazy_load_hdus or kwargs.get(\"checksum\") is True:\\n1238             # Go ahead and load all HDUs\\n1239             while hdulist._read_next_hdu():\\n1240                 pass\\n1241 \\n1242         # initialize/reset attributes to be used in \"update/append\" mode\\n1243         hdulist._resize = False\\n1244         hdulist._truncate = False\\n1245 \\n1246         return hdulist\\n1247 \\n1248     def _try_while_unread_hdus(self, func, *args, **kwargs):\\n1249         \"\"\"\\n1250         Attempt an operation that accesses an HDU by index/name\\n1251         that can fail if not all HDUs have been read yet.  Keep\\n1252         reading HDUs until the operation succeeds or there are no\\n1253         more HDUs to read.\\n1254         \"\"\"\\n1255         while True:\\n1256             try:\\n1257                 return func(*args, **kwargs)\\n1258             except Exception:\\n1259                 if self._read_next_hdu():\\n1260                     continue\\n1261                 else:\\n1262                     raise\\n1263 \\n1264     def _read_next_hdu(self):\\n1265         \"\"\"\\n1266         Lazily load a single HDU from the fileobj or data string the `HDUList`\\n1267         was opened from, unless no further HDUs are found.\\n1268 \\n1269         Returns True if a new HDU was loaded, or False otherwise.\\n1270         \"\"\"\\n1271         if self._read_all:\\n1272             return False\\n1273 \\n1274         saved_compression_enabled = compressed.COMPRESSION_ENABLED\\n1275         fileobj, data, kwargs = self._file, self._data, self._open_kwargs\\n1276 \\n1277         if fileobj is not None and fileobj.closed:\\n1278             return False\\n1279 \\n1280         try:\\n1281             self._in_read_next_hdu = True\\n1282 \\n1283             if (\\n1284                 \"disable_image_compression\" in kwargs\\n1285                 and kwargs[\"disable_image_compression\"]\\n1286             ):\\n1287                 compressed.COMPRESSION_ENABLED = False\\n1288 \\n1289             # read all HDUs\\n1290             try:\\n1291                 if fileobj is not None:\\n1292                     try:\\n1293                         # Make sure we\\'re back to the end of the last read\\n1294                         # HDU\\n1295                         if len(self) > 0:\\n1296                             last = self[len(self) - 1]\\n1297                             if last._data_offset is not None:\\n1298                                 offset = last._data_offset + last._data_size\\n1299                                 fileobj.seek(offset, os.SEEK_SET)\\n1300 \\n1301                         hdu = _BaseHDU.readfrom(fileobj, **kwargs)\\n1302                     except EOFError:\\n1303                         self._read_all = True\\n1304                         return False\\n1305                     except OSError:\\n1306                         # Close the file: see\\n1307                         # https://github.com/astropy/astropy/issues/6168\\n1308                         #\\n1309                         if self._file.close_on_error:\\n1310                             self._file.close()\\n1311 \\n1312                         if fileobj.writeonly:\\n1313                             self._read_all = True\\n1314                             return False\\n1315                         else:\\n1316                             raise\\n1317                 else:\\n1318                     if not data:\\n1319                         self._read_all = True\\n1320                         return False\\n1321                     hdu = _BaseHDU.fromstring(data, **kwargs)\\n1322                     self._data = data[hdu._data_offset + hdu._data_size :]\\n1323 \\n1324                 super().append(hdu)\\n1325                 if len(self) == 1:\\n1326                     # Check for an extension HDU and update the EXTEND\\n1327                     # keyword of the primary HDU accordingly\\n1328                     self.update_extend()\\n1329 \\n1330                 hdu._new = False\\n1331                 if \"checksum\" in kwargs:\\n1332                     hdu._output_checksum = kwargs[\"checksum\"]\\n1333             # check in the case there is extra space after the last HDU or\\n1334             # corrupted HDU\\n1335             except (VerifyError, ValueError) as exc:\\n1336                 warnings.warn(\\n1337                     f\"Error validating header for HDU #{len(self)} (note: Astropy \"\\n1338                     f\"uses zero-based indexing).\\\\n{indent(str(exc))}\\\\n\"\\n1339                     \"There may be extra bytes after the last HDU or the \"\\n1340                     \"file is corrupted.\",\\n1341                     VerifyWarning,\\n1342                 )\\n1343                 del exc\\n1344                 self._read_all = True\\n1345                 return False\\n1346         finally:\\n1347             compressed.COMPRESSION_ENABLED = saved_compression_enabled\\n1348             self._in_read_next_hdu = False\\n1349 \\n1350         return True\\n1351 \\n1352     def _verify(self, option=\"warn\"):\\n1353         errs = _ErrList([], unit=\"HDU\")\\n1354 \\n1355         # the first (0th) element must be a primary HDU\\n1356         if (\\n1357             len(self) > 0\\n1358             and (not isinstance(self[0], PrimaryHDU))\\n1359             and (not isinstance(self[0], _NonstandardHDU))\\n1360         ):\\n1361             err_text = \"HDUList\\'s 0th element is not a primary HDU.\"\\n1362             fix_text = \"Fixed by inserting one as 0th HDU.\"\\n1363 \\n1364             def fix(self=self):\\n1365                 self.insert(0, PrimaryHDU())\\n1366 \\n1367             err = self.run_option(option, err_text=err_text, fix_text=fix_text, fix=fix)\\n1368             errs.append(err)\\n1369 \\n1370         if len(self) > 1 and (\\n1371             \"EXTEND\" not in self[0].header or self[0].header[\"EXTEND\"] is not True\\n1372         ):\\n1373             err_text = (\\n1374                 \"Primary HDU does not contain an EXTEND keyword \"\\n1375                 \"equal to T even though there are extension HDUs.\"\\n1376             )\\n1377             fix_text = \"Fixed by inserting or updating the EXTEND keyword.\"\\n1378 \\n1379             def fix(header=self[0].header):\\n1380                 naxis = header[\"NAXIS\"]\\n1381                 if naxis == 0:\\n1382                     after = \"NAXIS\"\\n1383                 else:\\n1384                     after = \"NAXIS\" + str(naxis)\\n1385                 header.set(\"EXTEND\", value=True, after=after)\\n1386 \\n1387             errs.append(\\n1388                 self.run_option(option, err_text=err_text, fix_text=fix_text, fix=fix)\\n1389             )\\n1390 \\n1391         # each element calls their own verify\\n1392         for idx, hdu in enumerate(self):\\n1393             if idx > 0 and (not isinstance(hdu, ExtensionHDU)):\\n1394                 err_text = f\"HDUList\\'s element {idx} is not an extension HDU.\"\\n1395 \\n1396                 err = self.run_option(option, err_text=err_text, fixable=False)\\n1397                 errs.append(err)\\n1398 \\n1399             else:\\n1400                 result = hdu._verify(option)\\n1401                 if result:\\n1402                     errs.append(result)\\n1403         return errs\\n1404 \\n1405     def _flush_update(self):\\n1406         \"\"\"Implements flushing changes to a file in update mode.\"\"\"\\n1407         for hdu in self:\\n1408             # Need to all _prewriteto() for each HDU first to determine if\\n1409             # resizing will be necessary\\n1410             hdu._prewriteto(checksum=hdu._output_checksum, inplace=True)\\n1411 \\n1412         try:\\n1413             self._wasresized()\\n1414 \\n1415             # if the HDUList is resized, need to write out the entire contents of\\n1416             # the hdulist to the file.\\n1417             if self._resize or self._file.compression:\\n1418                 self._flush_resize()\\n1419             else:\\n1420                 # if not resized, update in place\\n1421                 for hdu in self:\\n1422                     hdu._writeto(self._file, inplace=True)\\n1423 \\n1424             # reset the modification attributes after updating\\n1425             for hdu in self:\\n1426                 hdu._header._modified = False\\n1427         finally:\\n1428             for hdu in self:\\n1429                 hdu._postwriteto()\\n1430 \\n1431     def _flush_resize(self):\\n1432         \"\"\"\\n1433         Implements flushing changes in update mode when parts of one or more HDU\\n1434         need to be resized.\\n1435         \"\"\"\\n1436         old_name = self._file.name\\n1437         old_memmap = self._file.memmap\\n1438         name = _tmp_name(old_name)\\n1439 \\n1440         if not self._file.file_like:\\n1441             old_mode = os.stat(old_name).st_mode\\n1442             # The underlying file is an actual file object.  The HDUList is\\n1443             # resized, so we need to write it to a tmp file, delete the\\n1444             # original file, and rename the tmp file to the original file.\\n1445             if self._file.compression == \"gzip\":\\n1446                 new_file = gzip.GzipFile(name, mode=\"ab+\")\\n1447             elif self._file.compression == \"bzip2\":\\n1448                 if not HAS_BZ2:\\n1449                     raise ModuleNotFoundError(\\n1450                         \"This Python installation does not provide the bz2 module.\"\\n1451                     )\\n1452                 new_file = bz2.BZ2File(name, mode=\"w\")\\n1453             else:\\n1454                 new_file = name\\n1455 \\n1456             with self.fromfile(new_file, mode=\"append\") as hdulist:\\n1457                 for hdu in self:\\n1458                     hdu._writeto(hdulist._file, inplace=True, copy=True)\\n1459                 if sys.platform.startswith(\"win\"):\\n1460                     # Collect a list of open mmaps to the data; this well be\\n1461                     # used later.  See below.\\n1462                     mmaps = [\\n1463                         (idx, _get_array_mmap(hdu.data), hdu.data)\\n1464                         for idx, hdu in enumerate(self)\\n1465                         if hdu._has_data\\n1466                     ]\\n1467 \\n1468                 hdulist._file.close()\\n1469                 self._file.close()\\n1470             if sys.platform.startswith(\"win\"):\\n1471                 # Close all open mmaps to the data.  This is only necessary on\\n1472                 # Windows, which will not allow a file to be renamed or deleted\\n1473                 # until all handles to that file have been closed.\\n1474                 for idx, mmap, arr in mmaps:\\n1475                     if mmap is not None:\\n1476                         mmap.close()\\n1477 \\n1478             os.remove(self._file.name)\\n1479 \\n1480             # reopen the renamed new file with \"update\" mode\\n1481             os.rename(name, old_name)\\n1482             os.chmod(old_name, old_mode)\\n1483 \\n1484             if isinstance(new_file, gzip.GzipFile):\\n1485                 old_file = gzip.GzipFile(old_name, mode=\"rb+\")\\n1486             else:\\n1487                 old_file = old_name\\n1488 \\n1489             ffo = _File(old_file, mode=\"update\", memmap=old_memmap)\\n1490 \\n1491             self._file = ffo\\n1492 \\n1493             for hdu in self:\\n1494                 # Need to update the _file attribute and close any open mmaps\\n1495                 # on each HDU\\n1496                 if hdu._has_data and _get_array_mmap(hdu.data) is not None:\\n1497                     del hdu.data\\n1498                 hdu._file = ffo\\n1499 \\n1500             if sys.platform.startswith(\"win\"):\\n1501                 # On Windows, all the original data mmaps were closed above.\\n1502                 # However, it\\'s possible that the user still has references to\\n1503                 # the old data which would no longer work (possibly even cause\\n1504                 # a segfault if they try to access it).  This replaces the\\n1505                 # buffers used by the original arrays with the buffers of mmap\\n1506                 # arrays created from the new file.  This seems to work, but\\n1507                 # it\\'s a flaming hack and carries no guarantees that it won\\'t\\n1508                 # lead to odd behavior in practice.  Better to just not keep\\n1509                 # references to data from files that had to be resized upon\\n1510                 # flushing (on Windows--again, this is no problem on Linux).\\n1511                 for idx, mmap, arr in mmaps:\\n1512                     if mmap is not None:\\n1513                         # https://github.com/numpy/numpy/issues/8628\\n1514                         with warnings.catch_warnings():\\n1515                             warnings.simplefilter(\"ignore\", category=DeprecationWarning)\\n1516                             arr.data = self[idx].data.data\\n1517                 del mmaps  # Just to be sure\\n1518 \\n1519         else:\\n1520             # The underlying file is not a file object, it is a file like\\n1521             # object.  We can\\'t write out to a file, we must update the file\\n1522             # like object in place.  To do this, we write out to a temporary\\n1523             # file, then delete the contents in our file like object, then\\n1524             # write the contents of the temporary file to the now empty file\\n1525             # like object.\\n1526             self.writeto(name)\\n1527             hdulist = self.fromfile(name)\\n1528             ffo = self._file\\n1529 \\n1530             ffo.truncate(0)\\n1531             ffo.seek(0)\\n1532 \\n1533             for hdu in hdulist:\\n1534                 hdu._writeto(ffo, inplace=True, copy=True)\\n1535 \\n1536             # Close the temporary file and delete it.\\n1537             hdulist.close()\\n1538             os.remove(hdulist._file.name)\\n1539 \\n1540         # reset the resize attributes after updating\\n1541         self._resize = False\\n1542         self._truncate = False\\n1543         for hdu in self:\\n1544             hdu._header._modified = False\\n1545             hdu._new = False\\n1546             hdu._file = ffo\\n1547 \\n1548     def _wasresized(self, verbose=False):\\n1549         \"\"\"\\n1550         Determine if any changes to the HDUList will require a file resize\\n1551         when flushing the file.\\n1552 \\n1553         Side effect of setting the objects _resize attribute.\\n1554         \"\"\"\\n1555         if not self._resize:\\n1556             # determine if any of the HDU is resized\\n1557             for hdu in self:\\n1558                 # Header:\\n1559                 nbytes = len(str(hdu._header))\\n1560                 if nbytes != (hdu._data_offset - hdu._header_offset):\\n1561                     self._resize = True\\n1562                     self._truncate = False\\n1563                     if verbose:\\n1564                         print(\"One or more header is resized.\")\\n1565                     break\\n1566 \\n1567                 # Data:\\n1568                 if not hdu._has_data:\\n1569                     continue\\n1570 \\n1571                 nbytes = hdu.size\\n1572                 nbytes = nbytes + _pad_length(nbytes)\\n1573                 if nbytes != hdu._data_size:\\n1574                     self._resize = True\\n1575                     self._truncate = False\\n1576                     if verbose:\\n1577                         print(\"One or more data area is resized.\")\\n1578                     break\\n1579 \\n1580             if self._truncate:\\n1581                 try:\\n1582                     self._file.truncate(hdu._data_offset + hdu._data_size)\\n1583                 except OSError:\\n1584                     self._resize = True\\n1585                 self._truncate = False\\n1586 \\n1587         return self._resize\\n1588 '}, {'name': 'hdulist', 'full_name': 'astropy.io.fits.hdu.nonstandard.FitsHDU.hdulist', 'documentation': '', 'implementation': '27     def hdulist(self):\\n28         self._file.seek(self._data_offset)\\n29         fileobj = io.BytesIO()\\n30         # Read the data into a BytesIO--reading directly from the file\\n31         # won\\'t work (at least for gzipped files) due to problems deep\\n32         # within the gzip module that make it difficult to read gzip files\\n33         # embedded in another file\\n34         fileobj.write(self._file.read(self.size))\\n35         fileobj.seek(0)\\n36         if self._header[\"COMPRESS\"]:\\n37             fileobj = gzip.GzipFile(fileobj=fileobj)\\n38         return HDUList.fromfile(fileobj, mode=\"readonly\")\\n39 '}, {'name': 'hdulist', 'full_name': 'astropy.wcs.tests.helper.SimModelTAB.hdulist', 'documentation': 'Simulates 2D data with a _spatial_ WCS that uses the ``-TAB``\\nalgorithm with indexing.', 'implementation': '57     def hdulist(self):\\n58         \"\"\"Simulates 2D data with a _spatial_ WCS that uses the ``-TAB``\\n59         algorithm with indexing.\\n60         \"\"\"\\n61         # coordinate array (some \"arbitrary\" numbers with a \"jump\" along x axis):\\n62         x = np.array([[0.0, 0.26, 0.8, 1.0], [0.0, 0.26, 0.8, 1.0]])\\n63         y = np.array([[-0.5, -0.5, -0.5, -0.5], [0.5, 0.5, 0.5, 0.5]])\\n64         c = np.dstack([x, y])\\n65 \\n66         # index arrays (skip PC matrix for simplicity - assume it is an\\n67         # identity matrix):\\n68         xb = 1 + self.nx // 3\\n69         px = np.array([1, xb, xb, self.nx + 1])\\n70         py = np.array([1, self.ny + 1])\\n71         xi = self.crval[0] + self.cdelt[0] * (px - self.crpix[0])\\n72         yi = self.crval[1] + self.cdelt[1] * (py - self.crpix[1])\\n73 \\n74         # structured array (data) for binary table HDU:\\n75         arr = np.array(\\n76             [(c, xi, yi)],\\n77             dtype=[\\n78                 (\"wavelength\", np.float64, c.shape),\\n79                 (\"xi\", np.double, (xi.size,)),\\n80                 (\"yi\", np.double, (yi.size,)),\\n81             ],\\n82         )\\n83 \\n84         # create binary table HDU:\\n85         bt = fits.BinTableHDU(arr)\\n86         bt.header[\"EXTNAME\"] = \"WCS-TABLE\"\\n87 \\n88         # create primary header:\\n89         image_data = np.ones((self.ny, self.nx), dtype=np.float32)\\n90         pu = fits.PrimaryHDU(image_data)\\n91         pu.header[\"ctype1\"] = \"RA---TAB\"\\n92         pu.header[\"ctype2\"] = \"DEC--TAB\"\\n93         pu.header[\"naxis1\"] = self.nx\\n94         pu.header[\"naxis2\"] = self.ny\\n95         pu.header[\"PS1_0\"] = \"WCS-TABLE\"\\n96         pu.header[\"PS2_0\"] = \"WCS-TABLE\"\\n97         pu.header[\"PS1_1\"] = \"wavelength\"\\n98         pu.header[\"PS2_1\"] = \"wavelength\"\\n99         pu.header[\"PV1_3\"] = 1\\n100         pu.header[\"PV2_3\"] = 2\\n101         pu.header[\"CUNIT1\"] = \"deg\"\\n102         pu.header[\"CUNIT2\"] = \"deg\"\\n103         pu.header[\"CDELT1\"] = self.cdelt[0]\\n104         pu.header[\"CDELT2\"] = self.cdelt[1]\\n105         pu.header[\"CRPIX1\"] = self.crpix[0]\\n106         pu.header[\"CRPIX2\"] = self.crpix[1]\\n107         pu.header[\"CRVAL1\"] = self.crval[0]\\n108         pu.header[\"CRVAL2\"] = self.crval[1]\\n109         pu.header[\"PS1_2\"] = \"xi\"\\n110         pu.header[\"PS2_2\"] = \"yi\"\\n111         for k, v in self.pc.items():\\n112             pu.header[k] = v\\n113 \\n114         hdulist = fits.HDUList([pu, bt])\\n115         return hdulist\\n116 '}, {'name': 'hdulist', 'full_name': 'astropy.io.fits.connect.read_table_fits.hdulist', 'documentation': None, 'implementation': 'hdulist = fits_open(input, character_as_bytes=character_as_bytes, memmap=memmap)'}, {'name': 'hdulist', 'full_name': 'astropy.io.fits.convenience.getheader.hdulist', 'documentation': None, 'implementation': 'hdulist, extidx = _getext(filename, mode, *args, **kwargs)'}]}\nThought:", "system_response": "The code_search tool returned several references to `HDUList`, which is the class in `astropy.io.fits` that represents a list of HDUs (Header/Data Units) in a FITS file. The documentation for `HDUList` indicates that it is the top-level FITS object returned when a FITS file is opened, and it can be constructed with a list of HDU objects. This is likely the starting point for creating a multi-extension FITS (MEF) file.\n\nThe `HDUList` class has methods like `append`, `insert`, and `fromfile` which seem relevant to constructing a FITS file with multiple extensions. To create a MEF file from scratch, one would typically start by creating a primary HDU, then append additional extension HDUs to the `HDUList`.\n\nTo provide a usage code example, I will need to construct a primary HDU and at least one extension HDU, then create an `HDUList` and append the HDUs to it. I will use the `PrimaryHDU` and `ImageHDU` or `BinTableHDU` classes to create these HDUs, as they are commonly used types of HDUs for image and table data respectively.\n\nI will now search for the `PrimaryHDU` and `ImageHDU` classes to find their constructors and methods that will help in creating a MEF file.\n\nAction:\n```\n{\n  \"action\": \"code_search\",\n  \"action_input\": {\n    \"names\": [\"PrimaryHDU\", \"ImageHDU\", \"BinTableHDU\"]\n  }\n}\n```"}